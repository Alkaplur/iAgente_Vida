from typing import Dict, Any, Literal
from langgraph.graph import StateGraph, END
from models import EstadoBot, EstadoConversacion, Cliente, ContextoConversacional
from agents.orquestador import orquestador_node, route_to_agent
from agents.extractor import extraer_datos_cliente, resetear_contexto_pregunta
from agents.needs_based_selling import needs_based_selling_node  # ‚Üê AGREGAR ESTA L√çNEA
from groq import Groq
from config import settings
import os
from agents.instructions_loader import cargar_instrucciones_cached
from agents.llm_client import get_llm_response


# Configurar tracing si est√° disponible
if os.getenv("LANGCHAIN_TRACING_V2"):
    os.environ["LANGCHAIN_TRACING_V2"] = "true"

# Cliente Groq
if settings.use_openai:
    from openai import OpenAI
    client = OpenAI(api_key=settings.openai_api_key)
else:
    from groq import Groq
    client = Groq(api_key=settings.groq_api_key)


def _manejar_respuesta_fallida(state: EstadoBot, contexto: ContextoConversacional) -> Dict[str, Any]:
    """
    Maneja cuando no se pudo interpretar la respuesta esperada
    """
    
    contexto.intentos_pregunta_actual += 1
    campo = contexto.ultimo_campo_solicitado
    
    print(f"‚ùå RESPUESTA NO V√ÅLIDA para {campo} (intento {contexto.intentos_pregunta_actual})")
    
    # Despu√©s de 2 intentos, hacer pregunta m√°s espec√≠fica
    if contexto.intentos_pregunta_actual >= 2:
        mensaje_ayuda = _generar_mensaje_ayuda_especifico(campo, state.mensaje_usuario)
        contexto.intentos_pregunta_actual = 0  # Reset para no entrar en bucle infinito
    else:
        mensaje_ayuda = _generar_aclaracion_rapida(campo, state.mensaje_usuario)
    
    return {
        "respuesta_bot": mensaje_ayuda,
        "cliente": state.cliente,
        "contexto": contexto,
        "etapa": EstadoConversacion.NEEDS_ANALYSIS
    }

def _generar_mensaje_ayuda_especifico(campo: str, mensaje_usuario: str) -> str:
    """Ayuda espec√≠fica para agentes sobre datos de clientes"""
    
    ayudas = {
        "num_dependientes": f"No pude entender '{mensaje_usuario}' como n√∫mero de dependientes de tu cliente. Responde SOLO con un n√∫mero:\n‚Ä¢ '0' si no tiene dependientes\n‚Ä¢ '2' si tiene 2 hijos\n‚Ä¢ '3' si tiene 3 personas a cargo",
        
        "edad": f"No reconoc√≠ '{mensaje_usuario}' como edad v√°lida de tu cliente. Necesito SOLO un n√∫mero entre 18 y 80.\nEjemplo: '35' (sin 'a√±os' ni otras palabras)",
        
        "ingresos_mensuales": f"No pude interpretar '{mensaje_usuario}' como ingresos de tu cliente. Dime SOLO la cantidad mensual en euros.\nEjemplos: '2500', '3000', '4500'",
        
        "nombre": f"Disculpa, no capt√© bien el nombre de tu cliente. Escribe el nombre completo claramente.\nEjemplo: 'Juan P√©rez' o 'Mar√≠a Gonz√°lez'",
        
        "profesion": f"No entend√≠ bien la profesi√≥n de tu cliente. S√© m√°s espec√≠fico.\nEjemplos: 'ingeniero', 'm√©dico', 'profesor', 'comercial'"
    }
    
    return ayudas.get(campo, f"Disculpa, no entend√≠ la informaci√≥n sobre tu cliente. ¬øPodr√≠as ser m√°s espec√≠fico?")

def _generar_aclaracion_rapida(campo: str, mensaje_usuario: str) -> str:
    """Aclaraciones para agentes sobre datos de clientes"""
    
    aclaraciones = {
        "num_dependientes": f"¬øTu cliente tiene {mensaje_usuario} dependientes? Confirma con solo el n√∫mero (0, 1, 2, etc.)",
        
        "edad": f"¬øTu cliente tiene {mensaje_usuario} a√±os? Escribe solo la edad en n√∫meros.",
        
        "ingresos_mensuales": f"¬øLos ingresos de tu cliente son {mensaje_usuario} euros mensuales? Escribe solo la cantidad.",
        
        "nombre": f"¬øTu cliente se llama {mensaje_usuario}? Si es correcto, confirma. Si no, escribe el nombre completo.",
        
        "profesion": f"¬øTu cliente trabaja como {mensaje_usuario}? Confirma o especifica mejor la profesi√≥n."
    }
    
    return aclaraciones.get(campo, f"¬øTe refieres a '{mensaje_usuario}' para tu cliente? Por favor confirma.")


def _solicitar_siguiente_dato(cliente: Cliente, campo: str, contexto: ContextoConversacional) -> Dict[str, Any]:
    """
    Solicita el siguiente dato faltante actualizando el contexto
    """
    
    pregunta = _generar_pregunta_inteligente(cliente, campo)
    
    # Actualizar contexto
    contexto.ultimo_campo_solicitado = campo
    contexto.ultima_pregunta = pregunta
    contexto.esperando_respuesta = True
    contexto.intentos_pregunta_actual = 0
    contexto.tipo_respuesta_esperada = _determinar_tipo_respuesta(campo)
    
    print(f"   Acci√≥n: Preguntando por {campo}")
    
    return {
        "respuesta_bot": pregunta,
        "cliente": cliente,
        "contexto": contexto,
        "etapa": EstadoConversacion.NEEDS_ANALYSIS
    }

def _generar_recomendacion_final(cliente: Cliente, contexto: ContextoConversacional) -> Dict[str, Any]:
    """
    Genera la recomendaci√≥n final cuando todos los datos est√°n completos
    """
    
    recomendacion = _generar_recomendacion_producto(cliente)
    mensaje_recomendacion = _presentar_recomendacion(cliente, recomendacion)
    
    # Resetear contexto
    contexto_limpio = resetear_contexto_pregunta(contexto)
    
    print(f"   Acci√≥n: Recomendando producto {recomendacion.tipo_cobertura}")
    
    return {
        "respuesta_bot": mensaje_recomendacion,
        "cliente": cliente,
        "contexto": contexto_limpio,
        "recomendacion_producto": recomendacion,
        "etapa": EstadoConversacion.COTIZACION
    }

def _determinar_tipo_respuesta(campo: str) -> str:
    """Determina qu√© tipo de respuesta esperamos"""
    
    tipos = {
        "nombre": "texto",
        "edad": "numero",
        "num_dependientes": "numero", 
        "ingresos_mensuales": "numero",
        "profesion": "texto",
        "estado_civil": "opcion",
        "nivel_ahorro": "numero"
    }
    
    return tipos.get(campo, "texto")

def _generar_pregunta_inteligente(cliente: Cliente, dato_faltante: str) -> str:
    """Genera preguntas para AGENTES sobre sus CLIENTES"""
    
    preguntas = {
        "nombre": "¬°Hola! Para ayudarte mejor con la venta, ¬øc√≥mo se llama tu cliente?",
        
        "edad": f"Perfecto. ¬øQu√© edad tiene {cliente.nombre}? (necesito el n√∫mero exacto para calcular las primas correctas)",
        
        "num_dependientes": f"¬ø{cliente.nombre} tiene hijos o personas que dependan econ√≥micamente de √©l/ella? Dime cu√°ntos (n√∫mero exacto del 0 al 10)",
        
        "ingresos_mensuales": f"Para proponer productos acordes a su capacidad, ¬øcu√°les son los ingresos mensuales aproximados de {cliente.nombre}? (en euros)",
        
        "profesion": f"¬øA qu√© se dedica profesionalmente {cliente.nombre}? Algunas profesiones tienen tarifas especiales o restricciones."
    }
    
    return preguntas.get(dato_faltante, f"¬øPodr√≠as contarme sobre {dato_faltante} de tu cliente?")

# IMPORTANTE: Agregar importaci√≥n al inicio del archivo
from agents.extractor import extraer_datos_cliente, resetear_contexto_pregunta

def quote_node(state: EstadoBot) -> Dict[str, Any]:
    """
    Agente especializado en generar cotizaciones basadas en:
    - Datos del cliente
    - Recomendaci√≥n de producto del needs-based selling
    """
    
    print(f"üí∞ QUOTE AGENT: Generando cotizaciones")
    print(f"   Cliente: {state.cliente.nombre}")
    print(f"   Recomendaci√≥n: {state.recomendacion_producto.tipo_cobertura if state.recomendacion_producto else 'Sin recomendaci√≥n'}")
    
    # Importar y usar el cotizador
    from agents.quote import calcular_cotizaciones, generar_presentacion
    
    try:
        # Generar cotizaciones basadas en cliente + recomendaci√≥n
        cotizaciones = calcular_cotizaciones(state.cliente, state.recomendacion_producto)
        
        # Generar presentaci√≥n de las cotizaciones
        mensaje_cotizaciones = generar_presentacion(state.cliente, cotizaciones)
        
        print(f"   Acci√≥n: {len(cotizaciones)} cotizaciones generadas")
        
        return {
            "respuesta_bot": mensaje_cotizaciones,
            "cotizaciones": cotizaciones,
            "etapa": EstadoConversacion.PRESENTACION_PROPUESTA
        }
        
    except Exception as e:
        print(f"‚ö†Ô∏è Error generando cotizaciones: {e}")
        return {
            "respuesta_bot": f"Disculpa {state.cliente.nombre}, estoy teniendo un problema t√©cnico generando las cotizaciones. ¬øPodr√≠as darme un momento?",
            "etapa": EstadoConversacion.COTIZACION
        }

def presentador_node(state: EstadoBot) -> Dict[str, Any]:
    """
    Agente especializado en:
    - Presentar cotizaciones de manera atractiva
    - Responder dudas sobre las opciones
    - Manejar objeciones
    - Guiar hacia el cierre
    """
    
    print(f"üìä PRESENTADOR: Manejando presentaci√≥n")
    print(f"   Cliente: {state.cliente.nombre}")
    print(f"   Cotizaciones disponibles: {len(state.cotizaciones)}")
    print(f"   Mensaje: '{state.mensaje_usuario}'")
    
    # Analizar qu√© necesita el cliente
    respuesta = _manejar_presentacion_y_dudas(state)
    
    return {
        "respuesta_bot": respuesta,
        "etapa": EstadoConversacion.PRESENTACION_PROPUESTA
    }

# ============= FUNCIONES AUXILIARES =============

def _extraer_informacion_cliente(cliente: Cliente, mensaje: str) -> Cliente:
    """Usar el agente extractor especializado"""
    return extraer_datos_cliente(cliente, mensaje)

def _identificar_datos_faltantes(cliente: Cliente) -> list:
    """Identifica datos esenciales que faltan"""
    
    esenciales = {
        "nombre": cliente.nombre,
        "edad": cliente.edad,
        "num_dependientes": cliente.num_dependientes,
        "ingresos_mensuales": cliente.ingresos_mensuales,
        "profesion": cliente.profesion
    }
    
    return [campo for campo, valor in esenciales.items() if valor is None]


    """Genera pregunta contextual para obtener el dato faltante"""
    
    preguntas = {
        "nombre": "¬°Hola! Para personalizar mejor mi asesor√≠a, ¬øc√≥mo te llamas?",
        "edad": f"Perfecto, {cliente.nombre}. ¬øQu√© edad tienes? Es importante para calcular las primas.",
        "num_dependientes": "¬øTienes hijos o personas que dependan econ√≥micamente de ti? Es fundamental para determinar la cobertura.",
        "ingresos_mensuales": "Para dise√±ar un seguro acorde a tu capacidad, ¬øcu√°les son tus ingresos mensuales aproximados?",
        "profesion": "¬øA qu√© te dedicas profesionalmente? Algunas profesiones tienen condiciones especiales."
    }
    
    return preguntas.get(dato_faltante, f"¬øPodr√≠as contarme sobre {dato_faltante}?")

def _generar_recomendacion_producto(cliente: Cliente):
    """Genera recomendaci√≥n de producto usando needs-based selling"""
    
    from models import RecomendacionProducto
    
    # L√≥gica de recomendaci√≥n basada en perfil
    if cliente.num_dependientes > 0 and cliente.edad < 45:
        # Familia joven - protecci√≥n completa
        return RecomendacionProducto(
            tipo_cobertura="completa",
            cobertura_principal="fallecimiento+invalidez",
            monto_recomendado=cliente.ingresos_mensuales * 12 * 10,
            justificacion=f"Con {cliente.num_dependientes} dependientes, necesitas protecci√≥n integral para asegurar su futuro",
            urgencia="alta",
            productos_adicionales=["invalidez", "enfermedades_graves"]
        )
    elif cliente.edad > 45:
        # Edad madura - ahorro + protecci√≥n
        return RecomendacionProducto(
            tipo_cobertura="premium",
            cobertura_principal="vida+ahorro",
            monto_recomendado=cliente.ingresos_mensuales * 12 * 8,
            justificacion="A tu edad, combinar protecci√≥n con ahorro es la estrategia m√°s inteligente",
            urgencia="media",
            productos_adicionales=["ahorro", "pensiones"]
        )
    else:
        # Joven sin dependientes - protecci√≥n b√°sica
        return RecomendacionProducto(
            tipo_cobertura="b√°sica",
            cobertura_principal="fallecimiento",
            monto_recomendado=cliente.ingresos_mensuales * 12 * 6,
            justificacion="Protecci√≥n b√°sica para comenzar a asegurar tu futuro",
            urgencia="media"
        )

def _presentar_recomendacion(cliente: Cliente, recomendacion) -> str:
    """Presenta la recomendaci√≥n de producto de manera persuasiva usando instrucciones"""
    
    # Cargar instrucciones del needs-based selling
    instrucciones_needs_based = cargar_instrucciones_cached('needs_based')
    
    prompt = f"""
{instrucciones_needs_based}

=== TAREA ESPEC√çFICA: PRESENTAR RECOMENDACI√ìN ===

CLIENTE: {cliente.nombre}, {cliente.edad} a√±os, {cliente.num_dependientes} dependientes, ‚Ç¨{cliente.ingresos_mensuales}/mes

RECOMENDACI√ìN GENERADA:
- Tipo: {recomendacion.tipo_cobertura}
- Cobertura: {recomendacion.cobertura_principal}
- Monto: ‚Ç¨{recomendacion.monto_recomendado:,.0f}
- Justificaci√≥n: {recomendacion.justificacion}

=== TU TAREA ===
Presenta esta recomendaci√≥n siguiendo las t√©cnicas de needs-based selling:

1. Conecta con las necesidades emocionales del cliente
2. Explica por qu√© es perfecta para su situaci√≥n espec√≠fica
3. Crea urgencia √©tica apropiada
4. Incluye una llamada a la acci√≥n suave
5. M√°ximo 5 l√≠neas, tono profesional y persuasivo

Usa las t√©cnicas de las instrucciones para crear urgencia y conectar emocionalmente.
"""
    
    try:
        response = get_llm_response(
            messages=[{"role": "user", "content": prompt}],
            temperature=0.4,
            max_tokens=500
        )
        return response.choices[0].message.content
    except:
        return f"Perfecto {cliente.nombre}, he analizado tu perfil y te recomiendo una cobertura {recomendacion.tipo_cobertura}. ¬øTe gustar√≠a que te prepare algunas cotizaciones?"

def _manejar_presentacion_y_dudas(state: EstadoBot) -> str:
    """Maneja la presentaci√≥n de cotizaciones y responde dudas usando instrucciones"""
    
    if not state.cotizaciones:
        return "Perm√≠teme generar las cotizaciones para ti..."
    
    # Cargar instrucciones del presentador
    instrucciones_presentador = cargar_instrucciones_cached('presentador')
    
    # Usar IA para manejar la conversaci√≥n de presentaci√≥n
    cotizaciones_texto = "\n".join([
        f"- {cot.tipo_plan}: ‚Ç¨{cot.prima_mensual}/mes, Cobertura: ‚Ç¨{cot.cobertura_fallecimiento:,.0f}"
        for cot in state.cotizaciones
    ])
    
    prompt = f"""
{instrucciones_presentador}

=== CONTEXTO DE PRESENTACI√ìN ===
CLIENTE: {state.cliente.nombre}
COTIZACIONES DISPONIBLES:
{cotizaciones_texto}

√öLTIMO MENSAJE DEL CLIENTE: "{state.mensaje_usuario}"

=== TU TAREA ===
Responde como especialista en cierre siguiendo las instrucciones del Presentador:

- Si pregunta por detalles ‚Üí explica las diferencias usando t√©cnicas de contraste
- Si tiene dudas ‚Üí resuelve con confianza y maneja objeciones
- Si muestra inter√©s ‚Üí gu√≠a hacia el siguiente paso con t√©cnicas de cierre
- Si pone objeciones ‚Üí usa las t√©cnicas espec√≠ficas de manejo de objeciones
- Si est√° indeciso ‚Üí aplica t√©cnicas de creaci√≥n de urgencia apropiadas

M√°ximo 6 l√≠neas, tono persuasivo pero no agresivo.
"""
    
    try:
        response = get_llm_response(
            messages=[{"role": "user", "content": prompt}],
            temperature=0.4,
            max_tokens=500
        )
        return response.choices[0].message.content
    except:
        return f"Tienes {len(state.cotizaciones)} opciones excelentes, {state.cliente.nombre}. ¬øQu√© te gustar√≠a saber sobre ellas?"

def _manejar_presentacion_y_dudas(state: EstadoBot) -> str:
    """Maneja la presentaci√≥n de cotizaciones y responde dudas"""
    
    if not state.cotizaciones:
        return "Perm√≠teme generar las cotizaciones para ti..."
    
    # Usar IA para manejar la conversaci√≥n de presentaci√≥n
    cotizaciones_texto = "\n".join([
        f"- {cot.tipo_plan}: ‚Ç¨{cot.prima_mensual}/mes, Cobertura: ‚Ç¨{cot.cobertura_fallecimiento:,.0f}"
        for cot in state.cotizaciones
    ])
    
    prompt = f"""
    Eres iAgente_Vida presentando cotizaciones.
    
    Cliente: {state.cliente.nombre}
    Cotizaciones disponibles:
    {cotizaciones_texto}
    
    √öltimo mensaje del cliente: "{state.mensaje_usuario}"
    
    Responde profesionalmente:
    - Si pregunta por detalles, explica las diferencias
    - Si tiene dudas, resuelve con confianza
    - Si muestra inter√©s, gu√≠a hacia el siguiente paso
    - Si pone objeciones, maneja con empat√≠a
    
    M√°ximo 6 l√≠neas.
    """
    
    try:
        response = get_llm_response(
            messages=[{"role": "user", "content": prompt}],
            temperature=0.4,
            max_tokens=500
        )
        return response.choices[0].message.content
    except:
        return f"Tienes {len(state.cotizaciones)} opciones excelentes, {state.cliente.nombre}. ¬øQu√© te gustar√≠a saber sobre ellas?"

# ============= CREAR EL GRAFO =============

def crear_grafo():
    """Crea el grafo multi-agente SIN bucles autom√°ticos"""
    
    workflow = StateGraph(EstadoBot)
    
    # A√±adir todos los nodos
    workflow.add_node("orquestador", orquestador_node)
    workflow.add_node("needs_based_selling", needs_based_selling_node)
    workflow.add_node("quote", quote_node)
    workflow.add_node("presentador", presentador_node)
    
    # Punto de entrada: siempre el orquestador
    workflow.set_entry_point("orquestador")
    
    # El orquestador decide a qu√© agente enviar
    workflow.add_conditional_edges(
        "orquestador",
        route_to_agent,
        {
            "needs_based_selling": "needs_based_selling",
            "quote": "quote",
            "presentador": "presentador",
            "__end__": END
        }
    )
    
    # CAMBIO CLAVE: Los agentes NO vuelven al orquestador autom√°ticamente
    # En su lugar, terminan y esperan el siguiente input del usuario
    workflow.add_edge("needs_based_selling", END)  # ‚Üê CAMBIO
    workflow.add_edge("quote", END)               # ‚Üê CAMBIO  
    workflow.add_edge("presentador", END)        # ‚Üê CAMBIO
    
    return workflow.compile()

# Crear instancia del grafo
graph = crear_grafo()
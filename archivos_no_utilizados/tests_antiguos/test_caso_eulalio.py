#!/usr/bin/env python3
"""
Test del caso real del usuario: Eulalio
"""
import os
import sys
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))

from models import Cliente, ContextoConversacional
from agents.extractor import extraer_datos_cliente
from agents.needs_based_selling import _generar_recomendacion_producto

def test_caso_eulalio():
    """Prueba el caso real: Eulalio, 55 aÃ±os, pintor, 3 hijos, casado"""
    
    print("ğŸ§ª TEST: Caso real - Eulalio")
    print("=" * 50)
    
    # Cliente inicial con nombre anterior (simulando el contexto)
    cliente = Cliente(id_cliente="eulalio_001", nombre="Que")  # Simular el estado anterior
    contexto = ContextoConversacional()
    
    # Mensaje del usuario
    mensaje = "se llama Eulalio, edad 55, trabaja como pintor, tiene 3 hijos, y esta casado, asi que hay 4 personas que dependen de el"
    
    print(f"ğŸ“ Mensaje: '{mensaje}'")
    print(f"ğŸ” Cliente antes: {cliente.nombre}, {cliente.edad}, {cliente.num_dependientes}")
    
    # Extraer datos con LLM
    cliente, cambios = extraer_datos_cliente(cliente, mensaje, contexto)
    
    print(f"âœ… Cliente despuÃ©s: {cliente.nombre}, {cliente.edad}, {cliente.num_dependientes}")
    print(f"ğŸ“Š Cambios detectados: {cambios}")
    
    # Mostrar datos extraÃ­dos
    print("\nğŸ“‹ DATOS EXTRAÃDOS:")
    print(f"   ğŸ‘¤ Nombre: {cliente.nombre}")
    print(f"   ğŸ‚ Edad: {cliente.edad}")
    print(f"   ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ Dependientes: {cliente.num_dependientes}")
    print(f"   ğŸ’¼ ProfesiÃ³n: {cliente.profesion}")
    print(f"   ğŸ’‘ Estado civil: {cliente.estado_civil}")
    print(f"   ğŸ’° Ingresos: {cliente.ingresos_mensuales}")
    
    # Generar recomendaciÃ³n (probar que no hay error matemÃ¡tico)
    try:
        recomendacion = _generar_recomendacion_producto(cliente)
        print(f"\nğŸ¯ RECOMENDACIÃ“N GENERADA:")
        print(f"   ğŸ“¦ Tipo: {recomendacion.tipo_cobertura}")
        print(f"   ğŸ›¡ï¸ Cobertura: {recomendacion.cobertura_principal}")
        print(f"   ğŸ’° Monto: â‚¬{recomendacion.monto_recomendado:,.0f}")
        print(f"   ğŸ“ JustificaciÃ³n: {recomendacion.justificacion}")
        print(f"   âš¡ Urgencia: {recomendacion.urgencia}")
        
        success = True
    except Exception as e:
        print(f"âŒ Error en recomendaciÃ³n: {e}")
        success = False
    
    # Verificar que se extrajeron los datos correctos
    # Nota: El LLM interpretÃ³ inteligentemente "4 personas que dependen de Ã©l" como 4 dependientes
    datos_correctos = (
        cliente.nombre == "Eulalio" and
        cliente.edad == 55 and
        cliente.num_dependientes == 4 and  # InterpretaciÃ³n inteligente: 3 hijos + 1 esposa
        cliente.profesion == "pintor" and
        cliente.estado_civil == "casado"
    )
    
    print(f"\n{'âœ… EXTRACCIÃ“N CORRECTA' if datos_correctos else 'âŒ EXTRACCIÃ“N INCORRECTA'}")
    print(f"{'âœ… RECOMENDACIÃ“N FUNCIONA' if success else 'âŒ ERROR EN RECOMENDACIÃ“N'}")
    
    if datos_correctos and success:
        print("\nğŸ‰ SISTEMA FUNCIONA CORRECTAMENTE CON CASO REAL")
        print("   âœ… Extractor LLM captura todos los datos")
        print("   âœ… No hay errores matemÃ¡ticos")
        print("   âœ… RecomendaciÃ³n generada sin problemas")
    
    return datos_correctos and success

if __name__ == "__main__":
    test_caso_eulalio()